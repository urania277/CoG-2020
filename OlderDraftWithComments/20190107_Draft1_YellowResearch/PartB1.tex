%NOTE: This doc formatted according to http://ec.europa.eu/research/participants/data/ref/h2020/call_ptef/pt/2018-2020/h2020-call-pt-erc-stg-2019_en.pdf

\documentclass[11pt,a4paper]{article}
\usepackage[left=2.0cm,top=2.0cm,right=2.0cm,bottom=1.5cm]{geometry}               
%\usepackage[subtle]{savetrees}
\usepackage[bibbreaks=normal, paragraphs=normal, floats=tight, mathspacing=tight, lists=tight, title=normal, margins=normal, wordspacing=normal, tracking=normal, charwidths=normal, bibnotes=normal, mathdisplays=tight, leading=normal, indent=normal, bibliography=tight, sections=tight]{savetrees} 

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{xspace}     
\usepackage{wrapfig}
\setlength\intextsep{0pt}

\usepackage{color}
\usepackage{colortbl}
\usepackage{amsmath} % Adds a large collection of math symbols                  
\usepackage{ifthen} % for conditional statements               
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{upgreek} % Adds in support for greek letters in roman typeset       
\usepackage{titling}
\usepackage{makecell}
\usepackage{pgfgantt}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{titlesec}
\usepackage{url,booktabs,amsmath,hepunits,abhepexpt,abhep,xcolor}%amsmath
\usepackage[colorlinks]{hyperref}    % Hyperlinks in references
\usepackage[all]{hypcap} % Internal hyperlinks to floats.

\newboolean{uprightparticles}
\setboolean{uprightparticles}{false} %Set to true to get roman particle symbols

%If we need more space we can investigate: https://tex.stackexchange.com/questions/273086/use-smaller-headheight-in-fancyhdr, https://tex.stackexchange.com/questions/271159/turn-off-fancyhdr-auto-spacing
\usepackage{fancyhdr}

\usepackage{rotating}

%\usepackage{fancyheadings}
\pagestyle{fancy}


% Playing with the page size 

\usepackage{array}
\newcolumntype{y}[1]{>{\raggedleft\arraybackslash}p{#1}}

%\renewcommand*{\arraystretch}{1.2}

%TB
%\addtolength{\oddsidemargin}{-10pt}
%\addtolength{\evensidemargin}{-10pt}
%\addtolength{\textwidth}{25pt}
%\addtolength{\textheight}{76pt}
%end TB

%\addtolength{\textfloatsep}{-2pt}
\setlength{\droptitle}{-44mm}

\setlength{\headwidth}{\textwidth}


\newboolean{articletitles}
\setboolean{articletitles}{false}

\usepackage{cite}
\usepackage{mciteplus}

\newboolean{inbibliography}

\titlespacing{\section}{0pt}{4pt}{0pt}
\titlespacing{\subsection}{0pt}{4pt}{0pt}
\titlespacing{\subsubsection}{0pt}{4pt}{0pt}

%\titlespacing{\section}{0pt}{\parskip}{0pt}
%\titlespacing{\subsection}{0pt}{\parskip}{0pt}
%\titlespacing{\subsubsection}{0pt}{\parskip}{0pt}

%Garamond saves space and looks way poncier
%\usepackage[T1]{fontenc}
%\usepackage[urw-garamond]{mathdesign}
\usepackage{ebgaramond}
\renewcommand\labelitemi{$\bullet$}


\usepackage{fontspec}

\setmainfont{EBGaramond-Regular}[
  BoldFont = EBGaramond-Bold,
  ItalicFont = EBGaramond-Italic,
  BoldItalicFont = EBGaramond-BoldItalic]
  
%\usepackage[cmintegrals,cmbraces]{newtxmath}
%\usepackage{ebgaramond-maths}
%\usepackage[T1]{fontenc}

% Helvetica for sans serif
% (scaled to match size of Palatino)
%\usepackage[scaled=0.90]{helvet}
%\usepackage{helvet}

\title{{\Large Part B1 - ERC Consolidator grant}}
\author{{\normalsize Caterina Doglioni}}
\date{}                                           % Activate to display a given date or no date

\usepackage[parfill]{parskip}

\begin{document}
\lhead{{\small Doglioni}}
\chead{{\small Part B1}}
\rhead{{\small REALDARK}}
\begin{center} 

{\Large\bf ERC Consolidator Grant 2020} \\
	{\Large\bf Research Proposal [Part B1]}  \\
 
\vspace{2cm} 
{\huge {\bf }}   \smallskip  

\vspace{2cm} 
{\Huge{REALDARK}} \\ 
\vspace{1cm} 
\vspace{1cm}
\end{center} 
\begin{tabular}{rcl}
Principal Investigator & : & Dr.~Caterina~Doglioni \\
Host Institution & : & Lund University \\ 
Proposal duration in months & : & 60 \\
\end{tabular}  
\vspace{2cm}


\begin{center} {\bf Summary}  \end{center}

The Standard Model of Particle Physics (SM) describes the fundamental components and interactions of ordinary matter. Despite the SM's success in predicting experimental results, it fails to account for the large excess of unobservable (Dark) matter in the Universe. A compelling hypothesis is that Dark Matter (DM) processes can be created from SM particle collisions as those produced by the Large Hadron Collider and recorded by the ATLAS detector at the CERN laboratory. 

In this project, I will continue leading the way in dark matter searches with innovative data taking techniques, with a team of postdoctoral researchers and students at Lund University. 

This research program makes use of real-time data analysis techniques to make the most of the vast amount of LHC data, expanding the ATLAS experiment’s physics program in a resource-constrained, data-rich environment. The technical outcomes of this project will be shared, providing valuable input to the wider experimental community in terms of technological advancements. 

We will employ and significantly extend techniques I have pioneered at the ATLAS detector to to search for evidence of processes related to dark matter at the LHC. 
We will pursue broad yet sensitive searches for dark matter models that can be discovered at the LHC (weakly massive interacting particles and dark sector particles) at a crucial time for the global quest for dark matter. 
The results of this project will provide new experimental support for the directions of future experiments and theoretical efforts. The searches in this project will yield either a discovery of a dark matter particle candidate ready to study in connection to astrophysical observations, or constraints on dark matter’s particle nature. 

\clearpage

\section*{Section A: Extended synopsis of the proposal} 

\medskip

\section{Aims and impact of this research project} 
\smallskip

The first years of data taking at the Large Hadron Collider (LHC)~\cite{LHC2008} at CERN yielded the discovery of a new fundamental particle, the Higgs boson~\cite{Khachatryan:2016vau}. With this and other notable results, the LHC data has confirmed the predictive power of the Standard Model (SM) of particle physics, the theory of fundamental particles and non-gravitational interactions. However, the amount of ordinary matter described by the SM is exceeded by a factor of five by a kind of unknown matter as determined by cosmological observations, called Dark Matter (DM)~\cite{Bertone:2016nfn}. 

%My big idea is to expand on successful searches for DM that I pioneered to look elsewhere because now it's the time to expand that program. 

Theoretical models that explain the abundance of DM in the universe include massive DM particles that interact weakly with ordinary particles, called WIMPs. These can be produced at the LHC in collisions of ordinary matter (see e.g.~\cite{Boveia:2018yeb} and references therein). 
Creating DM in controlled conditions enables the study of its interactions with ordinary matter, complementing searches for cosmological DM in direct and indirect detection experiments and astrophysical observations. %~\cite{Boveia:2018yeb}. 
WIMP Dark matter searches have been a flagship of the physics programmes of LHC experiments. In my Starting Grant (StG) I have led novel and comprehensive searches for particles that could reveal SM-DM interactions. I have ensured that the world-leading LHC constraints that resulted had a widespread impact in the global quest for DM, within a consistent theoretical framework that has been adopted by most LHC WIMP searches so far~\cite{Abercrombie:2015wmb}.  

Lack of evidence for WIMPs so far motivates a two-prong approach for DM searches at the LHC. In this Consolidator Grant proposal I will:
\begin{itemize}
    \item advance the state of the art for WIMP searches by enhancing their sensitivity to probe even rarer interactions.%SM-DM 
    \item deliver a new set of searches for models beyond the WIMP paradigm. These models postulate a new force akin to the strong interaction in the SM and could have so far escaped detection. 
\end{itemize}

The discovery of new, rare processes, at a time when traditional data-taking methods confirm the SM, mandates technical innovation. The LHC collides bunches of protons up to 30 million times per second. Recording and processing all this data is unfeasible: only a small fraction of interesting data can be selected by the experiment’s \textit{trigger systems} due to constraints on both processing and storage; the rest is discarded forever. This leads to a loss of sensitivity to large areas of parameter space for DM models. 

%Current data taking methods do not provide sensitivity to large areas of parameter space for DM models. 
The searches in this proposal will be enabled by innovative data-taking techniques at the earliest stage of data selection and processing, that increase the utility of the data recorded by the ATLAS experiment as a whole. These techniques, called Trigger Level Analysis (TLA\footnote{Analogue to the techniques of \textit{Data Scouting} in CMS~\cite{Khachatryan:2016ecr} and \textit{Turbo stream} in LHCb~\cite{Aaij:2016rxn}}, whose ATLAS proof-of-principle was delivered by my StG~\cite{Aaboud:2018fzt}) and Partial Event Building in ATLAS, reduce the size of the data used for physics analysis by a factor of \color{red}X\color{black}, overcoming the storage limitations that would otherwise force ATLAS and other LHC experiments to discard the majority of data of interest for many DM searches. %milliseconds after being taken
%taken, and deliver a dataset with unprecedented sensitivity. 

The physics results from this project, derived analysis products, and tools for their interpretation will be disseminated to the broader DM community in order to generate interdisciplinary impact.
%~\cite{Bertone:2018xtm}. 
%\end{itemize}
%	\item by exploiting the unprecedented sensitivity of the data recorded with these techniques by leading a comprehensive set of searches for DM models beyond the WIMP paradigm that . I will lead searches for new DM candidates and associated particles, which until now have escaped detection; % in this first phase of LHC data taking
%	\item by disseminating
The outcomes of this proposal will have a transformative effect in terms of both data taking innovations and in the global quest for DM. 
Data storage requirements are a widespread concern for LHC upgrades, as well as for many experiments where the increase in data collection is not matched by a proportional increase in resources~\cite{Alves:2017she,Allen:2018yvz}. 
This proposal will directly address this challenge, and develops solutions that can be ported beyond the LHC. 
Future collider projects will be prioritized in this decade~\cite{Strategy:2019vxc}, and a number of astroparticle and non-collider experiments will start taking data~\cite{APPECStrategy,Beacham:2019nyx}. 
This proposal delivers as outputs discoveries or constraints that are usable for these scientific communities by using Open Science tools, defining the future direction of DM research. 
% within the DM research community,
% Mention that HSF says RTA is crucial for 2020
% Mention that DM people says that they want this stuff done

I am uniquely suited to lead a team to deliver this ambitious and timely research program.  
As evidenced by my CV and track record, my profile combines both technical and scientific proficiency with leadership of large groups of scientists in both physics and data analysis tools. 
With my international collaborators and within my StG, I have led a paradigm shift in data taking techniques in ATLAS from software concept to publication and coordinate synergistic activities towards more efficient data selection and analysis that span the entire high energy physics and beyond~\cite{Alves:2017she}. I have authored a number of LHC searches for DM and new phenomena, and I have coordinated ATLAS- and LHC-wide working groups instrumental to the design of DM search strategies, such as the Dark Matter Working Group~\cite{DMWGWebsite}, and contributed to the prioritization of future experiments strategies in light of their sensitivity to uncovering the particle nature of DM. 
%~\footnote{Throughout this process, I have been responsible for definining benchmarks, gathering inputs and presenting the case for DM at colliders using various future facilities.}

\section{Innovation to the state of the art from this project} 
\smallskip

The presence of DM does not have an explanation in the SM. 
The absence of a particle explaining DM at the LHC and other experiments indicates that, if DM interacts with SM particles, these interactions must be very feeble and/or the experimental signals of DM must be subtle. 
At the same time, the enormous data rates of modern particle experiments present a challenge: with traditional data taking methods, it is not possible to record, process and store the large datasets required to reveal DM signals, and the majority of the data has to be discarded forever milliseconds after being taken. 
  
Two notable examples of discoveries that are impossible with traditional data taking methods are:
\begin{itemize} 
\item Rare processes where a new particle decays into ordinary matter, mimicked by more frequent SM-only processes.
These new processes are discarded together with the vast amount of irreducible SM background;
\item Processes where new particles leave non-standard signals in the detector. 
In these cases, the exact content of the collision is too time-consuming to reconstruct within the timing budget with which a decision to keep an event must be made. Therefore, the features that distinguish signal events from the more frequent background events are missing, and the event is discarded.
\end{itemize}

These discoveries map to two classes of models that explain the particle nature of dark matter, both able to reproduce the amount of DM measured in the universe (relic density). 

\begin{wrapfigure}{R}{0.5\textwidth} 
\begin{center}
\includegraphics[width=0.45\textwidth]{figs/SensitivityWIMP.png}
\caption{Sketch of sensitivity of WIMP searches in this proposal. \scriptsize \color{red} Make this sketch into a plot with the expected sensitivity of the searches. \color{black}\label{fig:pastFutureConstraints} }
\end{center}
\end{wrapfigure}

The first class of models corresponds to the current state of the art for LHC searches, where DM is a massive particle that interacts only weakly with SM particles -- a WIMP~\cite{Abercrombie:2015wmb,Boveia:2018yeb}. 
Due to their feeble interactions with the detector material, WIMPs are traditionally sought at collider experiments by selecting events with an energy imbalance where an invisible particle has escaped detection. 
These WIMPs can be produced from LHC proton-proton collisions through a new massive particle mediating the SM-DM interaction, analogously to the W and Z mediating the weak force. In addition to decaying into DM particles, this mediator will also decay into ordinary matter, through the same interactions responsible for its production. 
In my StG, I delivered a new set of searches where the DM mediator decays to two jets, using LHC Run-2 data. 
These searches have set the most stringent constraints to date for DM mediators with masses between 250 GeV and a TeV (see shaded \color{red} color \color{black} areas in Fig.~\ref{fig:pastFutureConstraints}). 
The search in the mediator mass range 450 GeV -- 1 TeV would not have been possible without the application of the TLA technique to jets, which overcomes the experiment's storage limitations by performing most of the initial data analysis and calibration already at the trigger level, retaining only a small amount of information for further analysis and discarding raw detector data. 
As already planned in my StG, in this proposal I will significantly extend this technique by enabling its use for photons, electrons and muons. 
I will first validate these data taking techniques with early LHC data by constraining mediators with masses above 400 GeV, via a world-first measurement of two-jet events using the TLA technique. I will subsequently exploit the full dataset containing photons and jets at the trigger level for more sensitive and lower-mass WIMP mediator searches (see shaded \color{red} color \color{black} areas in Fig.~\ref{fig:pastFutureConstraints}). 
%Change wording to WAF/VR

Motivated by constraints set on WIMPs, the second class of models postulates interactions that are much feebler, with much lighter mediators. 
These models~\cite{Strassler:2006im,Cohen:2017pzm} predict a multitude of new particles in addition to the DM candidate, mirroring the complexity of the SM in theories similar to the strong force. An unambiguous signal of these models are "dark QCD" jets which, in addition to visible particles, are comprised of invisible particles and light dark matter mediators which decay into low-energy electrons and muons~\cite{Curtin:2014cca}. 
Standard searches in two-jet final states are not optimally sensitive to these scenarios. %, since they escape detection and are discarded at the trigger level. 
This is because of the very large SM QCD backgrounds (a problem shared by WIMP mediator searches), and because the trigger system is unable to build and identify the characteristic features of dark QCD jets in time and they are considered noise. 
%shorten this sentence above
In this proposal, I will combine the TLA and the Partial Event Building technique for the first time in ATLAS to solve this problem, exploiting the work done to extend TLA to electrons and muons. %too much???
By augmenting the limited trigger level information with the full set of raw data but only in the region of interest behind the dark jets, I will bypass storage and processing limitations, and enable the reconstruction of features that distinguish signal from background at a later processing stage where more resources are available. 
I will use the dataset recorded with this technique to map the parameter space of dark QCD theories and discover or set stringent constraints on models never tested at the LHC. 
The unique dataset recorded with this new technique will be made available for other searches and measurements, extending the potential for discovery of the ATLAS physics programme. 

It is crucial that the results obtained in those searches are put into the broader context of the global search for dark matter. 
For this reason, I will continue leading the way to define community standards for LHC searches that highlight the complementarity of the results in the searches in this project to astroparticle, non-collider and cosmological results. 
Strong of the success of the Dark Matter Working Group that under my leadership set the standards for LHC WIMP search targets and for the presentation of results, I will continue leading initiatives that involve the active experimental and theoretical research community for non-WIMP DM scenarios~\cite{iDMEu}. 

%the impact of this proposal will not be limited to high energy physics but will be disseminated further afield to generate impact in DM direct detection and cosmological disciplines.  
% capitalizing on the information from many experiments coming online in the next decade

\section{Project organization and description} 
\smallskip


\begin{wrapfigure}{L}{0.6\textwidth} 
%\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.6\textwidth]{figs/WPs_shorter}
\caption{\label{fig:WPs} \footnotesize Schema of work packages and expected results.
%\color{red} This will become an in-line figure, possibly on the 1st page, after feedback. If needs be, the first section will be shortened. \color{black}
}
\end{center}

\vskip10pt
\end{wrapfigure}
%\end{figure}

The proposal consists of five logically interconnected work packages.
%to maximise impact. 
The work packages and their interconnections are indicated in Fig.~\ref{fig:WPs}. 
In \textbf{WP1} I will overcome the technological constraints that limit the sensitivity to a variety of physics phenomena including DM, with the use of non-standard data taking and recording techniques, and employ machine learning techniques for forward-looking improvements. 
In \textbf{WP2}, I will lead a programme of searches and measurements using the first LHC Run 3 data and in so doing commission the techniques developed in WP1. 
In \textbf{WP3 and WP4}, I will use the dataset recorded with the fully commissioned techniques developed in WP1 and WP2 to perform world-best and world-first searches for current and state-of-the-art dark matter models. 
In~\textbf{WP5}, I will interpret the results of those searches in coherent frameworks that go beyond model boundaries with the inclusion of input from LHC measurements and non-collider DM searches using Open Science tools, and work in synergy with the broader community for optimal contextualization and dissemination of results and tools. %transgress???

%\begin{description}

%\item[WP1] In WP1 I will overcome the technological constraints that limit the sensitivity to a variety of physics phenomena including DM, with the use of non-standard data taking and %recording techniques, and employ machine learning techniques for forward-looking improvements. 
%\item[WP2] In WP2, I will lead a programme of searches and measurements using the first LHC Run 3 data and in so doing commission the techniques developed in WP1. 
%\item[WP3, WP4] In WP3 and WP4, I will use the dataset recorded with the fully commissioned techniques developed in WP1 and WP2 to perform world-best and world-first searches for current and state-of-the-art dark matter models. 
%\item[WP5] In~\textbf{WP5}, I will interpret the results of those searches in coherent frameworks that transgress model boundaries with the inclusion of input from LHC measurements and non-collider DM searches using Open Science tools, and work in synergy with the broader community for optimal dissemination of results and tools. 
%\medskip

%\end{description}

\subsection*{WP1: Real-time analysis in ATLAS}

\begin{wrapfigure}{R}{0.4\textwidth} \includegraphics[width=0.4\textwidth]{figs/TLAPEB}
\caption{\label{fig:TLAPEB} \small Fraction of event rates recorded and trigger storage used for standard and TLA technique. 
The event rate recorded with TLA is much higher than the rate of events for standard data taking, for a much smaller amount of storage resources, as measured in 2017 ATLAS data-taking~\cite{ATLASComputing}. \scriptsize }
\end{wrapfigure}
%\color{red} If available, include estimates for this proposal. If not, change colors and only include Standard data taking and Trigger Level Analysis. Also, show how much this could be compressed if compression worked. \color{black}}

As the main technological advancement delivered by this proposal \textbf{my team and I will break the traditional paradigm of first recording the entirety of raw detector data and then analyzing it, by enabling ATLAS data to be reduced and processed in real-time} using the two techniques of TLA and Partial Event Building. As a pioneer of real-time analysis, I have delivered proof-of-concept studies for these techniques, but they must be now developed and commissioned on a much larger scale in order for me to exploit them for groundbreaking DM searches with the Run-3 dataset, and I will do so in WP1. 

\textbf{TLA} events only contain high level information reconstructed at the trigger level, and they are considerably smaller than events with full detector data. 
This technique therefore enables the recording of a much larger number of events within the same data rate, as shown in Fig.~\ref{fig:TLAPEB}.  
With my StG, I have shown that this technique is effective in a proof-of-concept use case of dark matter mediators~\cite{Aaboud:2018fzt}. 
Within this proposal I intend to extend this paradigm to photons, electrons and muons so that it can be used to extend the ATLAS experiment reach to a much larger set of searches and measurements. 

In the \textbf{Partial Event Building} technique, the information available to real-time analyses is augmented by a subset of the raw detector information in analyst-specified regions of the detector. This paradigm combines the data rate enhancements of real-time analysis with the added precision of full offline reconstruction in a user-configurable manner. 
Non-ordinary features signaling the presence of new phenomena can then be detected \textit{a posteriori}. 
This proposal will commission and use this technique for physics searches for the first time in ATLAS. 

Both of these techniques reduce data storage requirements, but these can be complemented by \textbf{further gains in data compression}. I will therefore pursue a method for data compression using machine learning (ML) algorithms where I have obtained preliminary results in collaboration with other ATLAS ML and computing experts. This is a forward-looking activity targeting the high-luminosity LHC run starting in 2026 as well as experiments beyond the LHC, as demonstrated by my ongoing collaborations with gravitational wave experiments.

\subsection*{WP2: Early measurements and searches}

During the shutdown between the Run-2 and Run-3 LHC data taking periods, the ATLAS experiment trigger system is undergoing significant upgrades~\cite{Aad:2013tqj}, and the trigger and reconstruction software is being rewritten~\cite{Stewart:2016pay}. 
Thorough commissioning and testing is mandatory, first with simulation and cosmic ray data, and subsequently with LHC commissioning data. 
In WP2, \textbf{my team and I will test a completely new software trigger framework and its performance via early measurements and searches}, using the already-established TLA techniques from Run-2~\cite{Aaboud:2018fzt}. This work will be documented by physics and technical publications.  

I will select events where at least two jets are detected and reconstructed in real-time within the trigger system, and compare the performance of their reconstruction and calibration at the trigger level with traditional data taking. 
%Improving the trigger-level reconstruction makes ATLAS data-taking more efficient as a whole. 
Beyond the technical publications documenting the new software framework and its commissioning with LHC data, this WP will lead to two physics publications:  
I will use this dataset for a world-first measurement of the jet cross section with trigger level data, and for the first Run-3 search for low-mass DM mediators. 
I will make extensive use of the Open Science tool RECAST~\cite{Schuy:2019awp} to preserve the end-to-end analysis workflow, from detector data to final plots so that we can take advantage of this work for the searches in WP3.  

\subsubsection*{WP3: WIMP dark matter mediator searches}

In WP3, \textbf{my team and I will use the TLA technique to search for decays of WIMP mediators in a scenario that is not fully constrained by existing searches}.
This search targets mediators with masses between 150 and 350 GeV, a mass range close to where the SM massive force mediators reside that is still poorly constrained, as neither traditional searches nor jet-only TLA searches have optimal sensitivity (see Fig.~\ref{fig:pastFutureConstraints}).  

We will employ the detector signature that I introduced to ATLAS during Run-2 using traditional data-taking methods, where the mediator is produced in association with an additional jet or photon~\cite{Aaboud:2019zxd} and yields the world-leading constraints in the upper mass range of this region. 
Performing this search with the TLA method, after the implementation of photons planned for WP1, will significantly increase its discovery potential, 
allowing for a factor of \color{red}N \color{black} more signal events to be recorded and a factor \color{red}M \color{black} improvement in signal-to-background ratio. 

During the 2022-2025 grant period, I will also be involved in the two-jet signature to search for mediators with masses above 350 GeV with the entire Run-3 dataset, together with a postdoc. 
This analysis will capitalize on the end-to-end analysis workflows set up in WP2 that make the analysis more efficient and ensure that the Run-3 results can be combined with the full Run-2 results and used to constrain a wide set of physics models~\cite{Kim:2019rhy}.   

\subsubsection*{WP4: Mapping dark Quantum Chromodynamics}

While the searches in WP2 are powerful probes of WIMPs, they are not sensitive to DM mediators whose interaction with the SM is even feebler, or to GeV-scale DM mediators. 
For this reason, in WP4 \textbf
{I will employ the combination of TLA and Partial Event Building developed in WP1 to discover signs of DM in a different class of models yielding new detector signatures}. 
This proposal focuses on two new searches.  

Firstly, we will search for evidence of models where the DM candidate particles are produced in association with a large number of other dark sector particles. 
Since these dark sector particles also interact through the SM's strong force, while the DM particles escape detection, this leads to \textit{semi-visible dark jets}~\cite{Cohen:2017pzm}.
Prototypes of these searches are being developed with Run-2 data, but they are limited to very high masses and to a narrow range of parameters of this model. 
In this proposal, I will scan a much larger part of the parameter space with the unique sensitivity warranted by this dataset, focusing on the region where this model can explain the relic density of DM~\cite{Bernreuther:2019pfb}. 

The second search builds on the semi-visible jet results and exploits the understanding of electrons and muons at the trigger level from WP1 to targets models where low-energy leptons from the decays of a light dark mediator or a dark Higgs boson are also found within the dark jets~\cite{Curtin:2014cca,Falkowski:2010gv}. %Cite Prestel?
Current searches are restricted to higher-energy leptons, and this dataset will extend the sensitivity to low-mass, low-energy and unusual objects that have been overlooked in searches so far. 

\subsubsection*{WP5: Contextualization, conceptualization, synergies}

WP5 focuses on defining frameworks and optimal search regions in the context of the global DM search community, and on the conceptualization and dissemination tools and results.
A dedicated WP ensures that the results of this project have a broad research impact that exploits both local synergies and synergies with other communities. 

Within WP5, I will pinpoint the optimal parameter space to be targeted for the new searches in WP4, and adapt the selection of events to be stored in the dataset accordingly. This will be done in collaboration with the local Lund theory group responsible for the most widely implementation of the theory in event generation software~\cite{Sjostrand:2007gs}, and using software that enables the use of precision results released by LHC collaborations~\cite{Butterworth:2016sqg} that has never been used in the context of these models before. 
In WP5 I will also ensure that all physics results from WP2-4 will be disseminated and implemented into Open Science tools (e.g. RECAST, HEPData) that meet the needs of other communities in terms of reproducibility, usability and complementarity. The successful experience of the Dark Matter Working Group for the LHC DM community is the stepping stone for a new, ambitious initiative that is being brought to the attention of the community~\cite{iDMEu} that will enable to bring the work from this project into a much broader context, including non-collider experiments, astrophysics, cosmology and multimessenger astronomy. 
An innovative aspect of this project is that its dissemination strategy is not limited to physics results but includes algorithms and tools. 
As I and many others advocated during the process leading to the update of the European Strategy of Particle Physics~\cite{Doglioni:2019fza}, challenges related to data acquisition, selection and analysis can be tackled more effectively and efficiently going beyond a single experiment's boundaries. 
For this reason, WP5 also includes collaborative work on data compression with other experiments where in a reduced storage footprint is necessary to increase the physics potential within the same resources, such as gravitational wave experiments. 

\section{Timeliness and timeline of the research program} 
\smallskip

I will lead a research team of two postdoctoral researchers and two students, sharing technical tasks and software and working in pairs on the two lines of physics analysis in this proposal.  
For WP1, the team will be joined by talented Lund University undergraduates that I have a track record of recruiting and training who will work on the forward-looking ML compression activities.
The research program spans the entire upcoming LHC data taking period (Run-3).
%and its timeline is shown in Fig.~\ref{fig:timeline}. 
The 2021-2026 period is the ideal time to advance the state-of-the-art in processing of large datasets and DM searches, as it ensures continued impact through a significant extension of my current successful StG research program that pioneered proof-of-principle real-time searches in ATLAS. 
The current LHC schedule includes an initial commissioning period where innovations can be deployed and tested via early measurements with start-up data, which forms the first part of this proposal (WP1 and WP2), and ready them for the second phase of the proposal where the LHC will be in production mode.   
The second phase of this proposal will use the wealth of LHC data delivered for novel DM searches, with a dataset that will be more than \color{red}twice \color{black} as sensitive to the physics observables of this proposal than the data collected so far (WP3 and WP4). 
Throughout the entire proposal, I will work in WP5 to share tools and results within the global DM community, to answer one of the most pressing questions of our universe with a discovery or by tracing the path to future search directions. 

%contextualize the results of the searches in this proposal and the LHC research program within
%The team will start with commissioning the techniques in WP1 (2021) as the the students fulfill their authorship qualification tasks in the trigger system. 
%The jet and photon TLA techniques will be ready in coincidence with early data taking in Summer 2021, while the delivery of TLA muons and electrons is planned for mid-2022. 
%Partial Event Building will also be commissioned with 2022 data, and the second

% Mention who asked you to do this rather than saying who you're doing this with
%In addition to further enhancing my standing as an expert in DM, 

%As a recognized expert in DM searches and collider data taking techniques with a track record of synergistic interdisciplinary activities, the impact of this proposal will not be limited to high energy physics but will be 
\clearpage

\setboolean{inbibliography}{true}
\bibliographystyle{LHCb}
\bibliography{researchrefs}

{\bf Note:} The PI is the editor of Refs.~\cite{Boveia:2018yeb,Abercrombie:2015wmb,Aaboud:2018fzt,Aaboud:2019zxd,Doglioni:2019fza}, the initiator of the activities in Refs.~\cite{DMWGWebsite,iDMEu} and an author of Refs.~\cite{Strategy:2019vxc,Alves:2017she} as well as of all publications by the ATLAS collaboration.
% -- Refs.~\cite{Alves:2008zz,CERN-LHCC-2014-016,LHCb:2011aa,Aaij:2013mga,Aaij:2014ywt}.
%The PI is the contact author within LHCb for Ref.~\cite{Aaij:2014ywt}.

\end{document}

%WORRD SALLADDD
\subsubsection*{WP3: WIMP dark matter mediator searches}

\begin{wrapfigure}{L}{0.25\textwidth} \includegraphics[width=0.25\textwidth]{figs/WIMPMediator}
\caption{\label{fig:WIMPMediator} \small Sketch of WIMP mediator model \scriptsize \color{red} Improve quality, consider adding DD/ID etc. \color{black}}
\end{wrapfigure}

This model is used by the majority of DM LHC searches and can reproduce the observed relic density. It can be used as a building block for more complex theories (e.g. those mentioned in WP4) since it can describe the behavior of these processes even with a small number of parameters. 


Both classes of models can explain the amount of dark matter in the universe from cosmological observations (the DM \textit{relic density}). 

%In this proposal I will map these discoveries to two classes of models which explain the particle nature of dark matter discussed in WP3 and WP4. %too kitchen sink
The data collected using these techniques represents an entirely new dataset that can extend the experimental reach of the ATLAS experiment with a similar amount of resources~\cite{Resonances}. 



The contextualization and dissemination of the results obtained will not be limited to high energy physics, as it will be extended further afield, to other experiments searching for DM. 

%and thanks to the presence of a strong theory group with world-leading expertise in the DM models I intend to look for. 

\subsubsection*{WP2: Early searches and measurements}



\subsubsection*{WP3: Dark Matter mediator searches}

%One of the most striking gaps in the knowledge of our universe is the nature of dark matter. All we know about dark matter so far comes from its gravitational and astrophysics observations and simulations; astrophysics also provides some tantalizing hints towards the existence of a new particle~\cite{HooperLeane} that are imperative to pursue~\footnote{Caveat about gravitation}. 

This WP furthers searches for WIMP models at the LHC using the Trigger Level Analysis technique, in a scenario that is not fully constrained by existing searches, by searching for the visible decays of the particles mediating the interaction between ordinary and dark matter. 

\begin{wrapfigure}{L}{0.25\textwidth} \includegraphics[width=0.25\textwidth]{figs/WIMPMediator}
\caption{\label{fig:WIMPMediator} \small Sketch of WIMP mediator model \scriptsize \color{red} Improve quality, consider adding DD/ID etc. \color{black}}
\end{wrapfigure}

%WIMP DM can be produced via interactions of SM particles at the LHC through a new force mediator (analogous to the W and Z for the Weak Force), as in Fig.~\ref{fig:WIMPMediator}. Here, quarks within the colliding protons couple to a mediator particle which decays to a pair of WIMPs or, through the same interaction responsible for mediator production, to two jets. 
This model is used by the majority of DM LHC searches and can reproduce the observed relic density. 

In WP3, I will search for the decays of mediators of DM in two-jet final states, accompanied by a photon or a jet. I have pioneered LHC searches for this signature in my StG using traditional data taking techniques as a way to look for new particles with lower masses with respect to what was possible in two-jet searches with the Trigger Level Analysis, and in this CoG I will implement the TLA technique in this kind of search, relying on the first ATLAS availability of TLA photons (\textbf{WP1}). This will lead to a major improvement to the sensitivity of particles in a region of phase space where the SM massive force mediators reside ($<$ 400 GeV), that is inaccessible with the same sensitivity by other kinds of searches, and that is motivated by a number of theoretical models beyond WIMP DM~\cite{ALP, HooperLeane}.  

\subsubsection*{WP4: Mapping dark/hidden sectors}

%Partly motivated by the constraints set on such particles by first-generation direct searches, and by the analyses I have led in the first phase of the LHC data taking, the DM community has recently started to generalize the flagship searches for these weakly interacting massive particles (WIMPs) by expanding the search program for particles with much weaker interactions with SM particles than what predicted by WIMP theories~\cite{FIMPs}. 
%This is a strong motivation for this project to enable detection of different DM candidates with broad theoretical connections, such as new particles from dark/hidden sectors~\cite{HiddenSector}. 

%While the searches in WP2 are powerful probes of WIMPs, they are not optimally sensitive to DM mediators whose interaction with the SM is even feebler. This is the case for “dark sector” or “hidden valley” models\cite{Zurek}, where the only connection between the SM and the DM particle spectrum occurs via a feebly coupled mediator particle (e.g. a photon-like particle with non-zero mass). Hidden valley models also postulate a multitude of dark sector particles, mirroring the complexity of the SM in a theory similar to the strong force.  
%These "dark Quantum Chromodynamics” (dark QCD) theories, where the fundamental constituents (e.g. dark quarks) fragment into a mixture of visible and invisible particles (dark hadrons), would still give rise to jets of particles. However, the particles forming the jet may be invisible, or only emerge after having partially traversed the detector material. Dark sector jets may also contain very light dark matter mediators that decay into low-energy electrons and muons. 
%Given the complexity of the parameter space driving the phenomenology of dark QCD, there are a wide range of possibility of how dark jets appear in the detector that need to be mapped. The majority of those possibilities currently escapes detection and are discarded at the trigger level, either because of the very large SM QCD  backgrounds (a problem shared by the search targets in WP3) or because the trigger system is unable to recognize their characteristic features in time and considers them noise.  
%The combination of TLA and partial event reconstruction is the solution to this problem: by recording a limited set of information reconstructed at the trigger level in addition to the full set of raw data behind the dark jet, we bypass storage limitations and we can reconstruct the features that distinguish signal from background at a later stage where more resources are available. 

While the dataset collected with those techniques allows mapping a large number of dark sector models, two classes that have not been searched at the LHC before are chosen to be investigated with Run-3 data in this proposal.

In the first class, one of the dark sector particles within the dark jet can easily make up the relic density of dark matter and is therefore completely invisible to the detector, leading to a \textit{semi-visible} jet. Since the main background for this signal is composed of mismeasured QCD jets, it is crucial that both QCD jets and dark jets are calibrated so that the measurement error and jitter can be minimized. As an expert in hadronic jets and their calibration, I will develop and employ techniques tailored for this specific search. 
In the second class of models, low-energy leptons from the decays of e.g. a light dark mediator or from a dark Higgs boson are an integral part of the dark jet, mirroring the way as QCD particle showers develop an interleaved electromagnetic component. The main challenge of searches for these models is the development of reconstruction algorithms and calibrations for these leptons, and we will rely on existing algorithm that the ATLAS collaboration has already developed but not yet widely used for physics measurements and implement them in the trigger level reconstruction within WP1. 

As part of WP5, the parameter space that will be investigated in these models will be carefully chosen by considering the constraints from past searches for the individual particles within the dark jet (e.g.~\cite{DarkPion})  and LHC measurements of the development of QCD jets that are sensitive to changes in the structure of jets, using a software program that enables the use of precision results released by the ATLAS, CMS and LHCb collaboration to be used to constrain the parameter space of new physics models~\cite{CONTUR}. 

\subsubsection*{WP5: Conceptualization, contextualization, synergies}

%\begin{wrapfigure}{R}{0.5\textwidth} 
%\begin{figure}[h!]
%\begin{center}
%\includegraphics[width=0.7\textwidth]{figs/flavorprobes.pdf}
%\caption{\label{fig:scales} Energy scales of generic NP models probed by heavy flavor observables. The energies accessible to searches at the LHC and a potential $100~\TeV$ future collider (FCC) are indicated. Figure adapted from~\cite{neubert:scales}}
%\end{center}
%\end{wrapfigure}
%\end{figure}


\section{Timeliness of the research program and appropriateness of the PI and team} 
\smallskip

This research program spans the entire upcoming LHC data taking period (Run-3). The 2021-2026 period is the ideal time to advance the state-of-the-art in processing of large datasets and DM searches, ensuring continued impact through a significant extension of my current successful StG research program that relies on novel data-taking techniques. The LHC schedule includes an initial commissioning period where innovations can be deployed and tested via early measurements with start-up data, which forms the first part of this proposal. The second phase of this proposal will use the wealth of data delivered by the LHC during the fully-commissioned data taking period for novel DM searches, with a dataset that will be more than twice as sensitive to the physics observables of this proposal than the data collected so far. 

I am uniquely suited to deliver an ambitious and timely research program in which I will lead a research team of two postdoctoral researchers and two students, complemented by talented Lund University undergraduates that I have a track record of recruiting and training.
As evidenced by my CV and track record, my profile combines both technical and scientific proficiency with leadership of large groups of scientists in both physics and data analysis tools. 
With my international collaborators and within my StG, I have led a paradigm shift in data taking techniques in ATLAS from software concept to publication \textbf{[and I am now HSF convenor]}. I have authored a number of LHC searches for DM and new phenomena, and I have coordinated ATLAS- and LHC-wide working groups instrumental to the design of DM search strategies~\cite{DMWG}. 
As an internationally recognised expert in the field, I have been invited to write review articles on the subject area of this proposal~\cite{Buchmueller:2017qhf, Boveia:2018yeb}, and have contributed to the European Strategy update, which defines the next 10 years of Europe-wide and international research in HEP, as one of the scientific secretaries of both the Dark Matter and Beyond the Standard Model Physics Planning Groups~\cite{Strategy:2019vxc}.


% Mention who asked you to do this rather than saying who you're doing this with
%In addition to further enhancing my standing as an expert in DM, 

As a recognized expert in DM searches and collider data taking techniques with a track record of synergistic interdisciplinary activities, the impact of this proposal will not be limited to high energy physics but will be disseminated further afield to generate impact in DM direct detection and cosmological disciplines.  

\section{Project planning}
\smallskip

Minigantt

I will lead a research team consisting of two postdoctoral researchers and two PhD students. 

\footnote{The first two years of Run-3 are the ideal opportunity to use the  to . 
The initial LHC accelerator plan for Run-3 foresees that the first two years (2021-2022) will be used as a ramp-up for the production data taking period, with the majority of the dataset being collected in (2023-2024)~\cite{SomeRandomEuropeanStrategyPresentationOrTooMuch}.}.

%\begin{figure}[h!]
%\begin{center}
%\includegraphics[width=0.7\textwidth]{figs/timeline_new.pdf}
%\caption{\label{fig:timeline} Timeline of the proposal.}
%\end{center}
%\end{figure}

%The LHC will begin Run III with a commissioning period during %which the software trigger will be exercised. A detector %commissioning paper will be published in Q2 2021, and a %performance paper in Q4 2021 where the new exclusive trigger %selections will be used to highlight the increased efficiency %with respect to Run II. 


\section{Conclusions}

%CAN BE USED This proposal will solve this issue by enabling the ATLAS experiment to record data in a new manner. This will permit, for the first time, this wealth of recorded data to be used for early measurements and new dark matter searches, and propagates the results and the developed tools to the broader community. \textbf{Mention the tools somewhere}

\clearpage
%\addcontentsline{toc}{section}{References}
\setboolean{inbibliography}{true}
\bibliographystyle{LHCb}
\bibliography{researchrefs}


\clearpage

%\input{CF/CV_CF}

\section*{Section B: Curriculum Vitae}

\clearpage

\section*{Appendix: All ongoing and submitted grants and funding of the PI}

%\input{CF/FundingID_CF}

\clearpage

\section*{Section C: Early achievements track record}

%\input{CF/TrackRecord_CF}

\end{document}  
