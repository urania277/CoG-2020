%Boilerplate LHC is great
The first years of data taking at the largest discovery machine ever built by humankind, the Large Hadron Collider (LHC) at the CERN laboratory in Geneva, have yielded experimental confirmation of the predictive power of the Standard Model (SM) of particle physics.
While all ordinary fundamental particles and their non-gravitational interactions are described in the SM, the complete lack of an explanation for the presence of Dark Matter (DM) evidenced from astrophysical observations indicates that the SM is an incomplete theory. The dominance of DM over ordinary matter remains one of the main puzzles for high energy physics and astrophysics. 

The absence so far of clues at the LHC or other experiments indicates that, if DM interacts with SM particles, these interactions must be very feeble and/or the experimental signals of DM are subtle, requiring large datasets to reveal. 
At the same time, the enormous data rates of modern particle physics experiments present a data acquisition challenge: with traditional methods, it is not possible to record and store these large datasets when the rare processes are buried in high-rate backgrounds. 

This proposals overcomes this challenge and enables the discovery of rare, subtle DM signals. 
%Maybe add: the LHC is sensitive to DM if we assume that there are some interactions…
As a senior lecturer at Lund University and established leader in DM searches, I will direct 
%leader/lead but this sounds like I'm doing jack shit
a team of students and researchers to search for signs of DM and new phenomena in the wealth of LHC data collected in 2021-2026 and recorded by the ATLAS experiment. We will employ a new data-taking paradigm to discover signals of broad classes of compelling dark matter models and new phenomena that are rare or have so far been neglected. 

Within \textsc{REALDARK} we will significantly extend the capability of the ATLAS experiment to perform \textit{real-time analysis}. This techniques overcomes the traditional paradigm of first recording all detector data and then analyzing it by performing the data analysis as close to the detector as possible, so that the majority of raw detector data can be dropped. We will also seek further reduction in data storage using machine learning algorithms for data compression. This work is grouped in \textbf{Work Package (WP) 1}.

We will deploy and validate these new real-time analysis techniques with well-established generic searches for new phenomena that can already lead to groundbreaking results in the earlier stages of LHC data taking (\textbf{WP2}).

Taking full advantage of the LHC dataset and of the novel data taking techniques, we will perform a set of searches with unprecedented sensitivity to two broad classes of DM models: 
\begin{itemize}
\item models in which DM is composed of a weakly interacting massive particle (WIMP). These  represent the current state-of-the-art in terms of benchmarks at colliders and experiments sensitive to cosmological DM (\textbf{WP3}).
\item more complex models that predict dark matter candidates among other “dark sector” particles. These models leave signals that are generally more difficult to detect than WIMP signals, as they escape traditional detector reconstruction techniques (\textbf{WP4}).
\end{itemize}

The outcome of those searches will be either a discovery to be characterized or a constraint on the parameter space of these models that will guide future experiments. The dissemination of these results and of the tools used to make them possible, in conference talks, peer-reviewed papers, reinterpretation material and software, will have a lasting impact in the broader DM and experimental community (\textbf{WP5}).

\textbf{[Add here briefly: why me, why Lund]}